{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Dataset Extraction & Augmentation** \\\\\n","Spring 2024, Senior Thesis \\\\\n","Christian Granados\n","\n","Details the datasets used for image segmentation and links to their sources. This notebook will also outline and preform data augmentation techniques to these datasets due to their low volume. Techniques will be guided by modifications preformed in research papers within the literature review portion of this senior thesis.\n","\n","HAM10000 is a skin lesion, biomedical image segmentation dataset. This was choosen for its large amount of data, large diversity of data, and expert-tuned binary masks (of which the process for generation has been detailed in a research paper)\n","\n","[Link to Harvard Dataverse Page](https://dataverse.harvard.edu/dataset.xhtml;jsessionid=38ff811c3afc0eb08b5092945918?persistentId=doi:10.7910/DVN/DBW86T) \\\\\n","[Link to Segmentation Masks Dataset](https://www.kaggle.com/datasets/tschandl/ham10000-lesion-segmentations) \\\\\n","[Humanâ€“Computer Collaboration for Skin Cancer Recognition](https://www.nature.com/articles/s41591-020-0942-0)\n","\n","**Methods**\n","- Addition of Random Noise (Salt & Paper)\n","- Subselection via Cropping\n","- Flipping, Rotation, and Scaling\n","- Brightness & Contrast"],"metadata":{"id":"ulJp2FPB8C0N"}},{"cell_type":"code","source":["from google.colab.patches import cv2_imshow\n","from collections import defaultdict\n","import matplotlib.pyplot as plt\n","from google.colab import files\n","from scipy.stats import norm\n","import seaborn as sns\n","import pandas as pd\n","import numpy as np\n","import random\n","import string\n","import glob\n","import cv2\n","import os\n","import re"],"metadata":{"id":"9c-w4AAv8ZLy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"POp4f59rgoZg","outputId":"3ca42cc0-c551-481a-a28e-8a0afaaad734","executionInfo":{"status":"ok","timestamp":1714553612190,"user_tz":420,"elapsed":1117,"user":{"displayName":"Christian A Granados","userId":"12347134257870755255"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["def add_random_sp_noise(img, prop = 0.005):\n","    '''\n","    Adds salt and pepper noise to the inserted RGB image.\n","    Prop denotes the proportion of the total image\n","    that is composed of noise. Will iterate through all\n","    channels an image has. Assumed pixel values\n","    between 0 and 255.\n","\n","    img - cv2.Mat object or numpy array\n","    prop - float between 0 and 1 (inclusive)\n","    '''\n","    imgc = img.copy()\n","\n","    b, w = 0, 255 # Greyscale\n","    if imgc.shape[2] == 3: #RGB\n","        b = np.array([0, 0, 0], dtype='uint8')\n","        w = np.array([255, 255, 255], dtype='uint8')\n","    probs = np.random.random(imgc.shape[:2])\n","    imgc[probs < (prop / 2)] = b\n","    imgc[probs > (1 - (prop / 2))] = w\n","\n","    return imgc"],"metadata":{"id":"gAFKn6t3KYDh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def random_crop_selection(img, mask, sx, sy):\n","    '''\n","    Returns a random sub-selection of the image and\n","    ground-truth mask that is sx wide and sy tall.\n","\n","    img, mask - cv2.Mat objects or numpy arrays\n","    sx, sy - integers > 0 and < size of image\n","\n","    '''\n","    imgc = img.copy()\n","    maskc = mask.copy()\n","    sx, sy = int(sx), int(sy)\n","\n","    h, w, c = imgc.shape\n","    hhigh, whigh = w - sx, h - sy\n","\n","    rx = np.random.randint(low = 0, high = whigh, size = 1, dtype = int)[0]\n","    ry = np.random.randint(low = 0, high = hhigh, size = 1, dtype = int)[0]\n","\n","    return (\n","        imgc[ry : ry + sy, rx: rx + sx],\n","        maskc[ry : ry + sy, rx: rx + sx]\n","        )"],"metadata":{"id":"UQ0hinYVRHMv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def rand_flip_rot_scale(img, mask, flip = True, rotate = True, rot_max = 360, scale = True, scal_min = 0.8, scal_max = 2.0):\n","    '''\n","    Depending on whther flip, rotate, and scale are\n","    set to true for the passed in image and mask, will\n","    apply a random flip (horiz, vert, both, none), rotate\n","    by a uniformly random degree amount [0, 360], and\n","    scale the image by a uniformly random float values\n","    on [scal_min, scal_max]\n","\n","    img, mask - cv2.Mat objects or numpy arrays\n","    flip, rotate, scale - boolean; whether to use functionality or not\n","    rot_max - integer [0, 360]; maximum degrees to rotate image by\n","    scal_min, scale_max - float [0, inf); minimum and maximum scale factors\n","    '''\n","    imgc = img.copy()\n","    maskc = mask.copy()\n","    h, w, c = imgc.shape\n","\n","    t = np.random.randint(low = -2, high = 2, size = 1, dtype = int)[0]\n","    if flip and (t != -2):\n","        imgc = cv2.merge([cv2.flip(imgc[:, :, i], t) for i in range(c)])\n","        maskc = cv2.merge([cv2.flip(maskc[:, :, i], t) for i in range(c)])\n","\n","    scl = 1.0\n","    if scale:\n","        scl = np.random.random_sample(size = 1)[0] * (scal_max - scal_min) + scal_min\n","\n","    if rotate:\n","        r = np.random.randint(low = 0, high = rot_max + 1, size = 1, dtype = int)[0]\n","        h, w, c = imgc.shape\n","        center = (w // 2, h // 2)\n","        rot_mat = cv2.getRotationMatrix2D(center = center, angle = r, scale = scl)\n","        imgc = cv2.warpAffine(imgc, rot_mat, (w, h))\n","        maskc = cv2.warpAffine(maskc, rot_mat, (w, h))\n","\n","    return (imgc, maskc)\n"],"metadata":{"id":"5L7f7k9peaoO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def rand_brig_cont(img, brig_min = -75, brig_max = 75, cont_min = 0.7, cont_max = 1.3):\n","    '''\n","    For an image and mask, will uniformly\n","    select a brightness modification value\n","    between brig_min and brig_max. Then a\n","    constrast value between cont_min and\n","    cont_max that details constrast.\n","\n","    img, mask - cv2.Mat or Numpy array\n","    brig_min, brig_max - (-inf, inf) float\n","    cont_min, cont_max - float (0, inf]\n","    '''\n","    imgc = img.copy()\n","\n","    c = np.random.random_sample(size = 1)[0] * (cont_max - cont_min) + cont_min\n","    b = np.random.random_sample(size = 1)[0] * (brig_max - brig_min) + brig_min\n","    adj_imgc = cv2.convertScaleAbs(imgc, alpha = c, beta = b)\n","\n","    return adj_imgc"],"metadata":{"id":"boxieAS18Vz5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Retrieves mask and images file names from downloaded HAM10000 dataset. Removes duplicates, non-matching images/masks, or those in the wrong format."],"metadata":{"id":"vJ7IBODbdhxL"}},{"cell_type":"code","source":["imgs_list = glob.glob('/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_IMGS/*')\n","masks_list = glob.glob('/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_MASKS/*')\n","\n","a = {}\n","for f in imgs_list:\n","    try:\n","        cf = re.search(r\"0(\\d+)\\.jpg\", f).group(1)\n","        if cf not in a:\n","            a[cf] = 1\n","        else:\n","            os.remove(f)\n","    except:\n","        print(f)\n","        os.remove(f)\n","\n","for f in masks_list:\n","    try:\n","        cf = re.search(r\"0(\\d+)_segmentation\\.png\", f).group(1)\n","        if cf not in a:\n","            os.remove(f)\n","        else:\n","            a[cf] -= 1\n","    except:\n","        print(f)\n","        os.remove(f)\n","\n","for k, v in a.items():\n","    if v == 1:\n","        os.remove(\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_IMGS/ISIC_0\" + str(k) + \".jpg\")\n","    elif v == -1:\n","        os.remove(\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_MASKS/ISIC_0\" + str(k) + \"_segmentation.png\")"],"metadata":{"id":"k7Xrx8wmal4_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Resizing images from 450 x 600 $\\to$ 256 x 256. Initially the images will be center cropped to get images of size 450 x 450, then rescaled to 256 x 256. Square images of a power of two (2) will make model building signficantly easier.  "],"metadata":{"id":"AZGpCFY4Rh96"}},{"cell_type":"code","source":["i = 0\n","for f in imgs_list:\n","    img = cv2.imread(f).copy()\n","    h, w, c = img.shape\n","\n","    if h > 450:\n","        d = (h - 450) // 2\n","        img = img[d:d+450, :, :]\n","\n","    if w > 450:\n","        d = (w - 450) // 2\n","        img = img[:, d:d+450, :]\n","\n","    resimg = cv2.resize(img, (256, 256), interpolation = cv2.INTER_CUBIC)\n","    fid = \"0\" + re.search(r\"0(\\d+)\\.jpg\", f).group(1)\n","    fpath = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_IMGS_CROP/ISIC_\" + fid + \".jpg\"\n","    tmp = cv2.imwrite(fpath, resimg)\n","    if not tmp:\n","        print(tmp, i)\n","    i += 1\n"],"metadata":{"id":"7DsgiZUjT4rD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i = 0\n","for f in masks_list:\n","    img = cv2.imread(f).copy()\n","    h, w, c = img.shape\n","\n","    if h > 450:\n","        d = (h - 450) // 2\n","        img = img[d:d+450, :, :]\n","\n","    if w > 450:\n","        d = (w - 450) // 2\n","        img = img[:, d:d+450, :]\n","\n","    resimg = cv2.resize(img, (256, 256), interpolation = cv2.INTER_CUBIC)\n","    fid = \"0\" + re.search(r\"0(\\d+)_segmentation\\.png\", f).group(1)\n","    fpath = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_MASKS_CROP/ISIC_\" + fid + \"_segmentation.png\"\n","    tmp = cv2.imwrite(fpath, resimg)\n","    if not tmp:\n","        print(tmp, i)\n","    i += 1"],"metadata":{"id":"76GTI4BoWnTG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Original Dataset:** 10k \\\\\n","**Salt & Pepper Noise:** 2.5K \\\\\n","**Random Crop + Salt & Pepper Noise:** 2.5k \\\\\n","**Flip, Rotate, Scale + Salt & Pepper Noise:** 2.5k \\\\\n","**Brightness, Contrast + Salt & Pepper Noise:** 2.5k"],"metadata":{"id":"mpnr-ihV9fqF"}},{"cell_type":"code","source":["if not os.path.exists(\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_IMGS_AUG/\"):\n","    os.mkdir(\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_IMGS_AUG/\")\n","\n","if not os.path.exists(\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_MASKS_AUG/\"):\n","    os.mkdir(\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_MASKS_AUG/\")"],"metadata":{"id":"ou60ztUj-L20"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i = 0\n","for f in random.sample(imgs_list, 2500):\n","    uuid = ''.join(random.choices(string.ascii_uppercase + string.digits, k = 10))\n","    fid = \"0\" + re.search(r\"0(\\d+)\\.jpg\", f).group(1)\n","\n","    fnid = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_IMGS_CROP/ISIC_\" + fid + \".jpg\"\n","    mid = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_MASKS_CROP/ISIC_\" + fid + \"_segmentation.png\"\n","\n","    f_nu = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_IMGS_AUG/IMGS_SP_\" + uuid + \".jpg\"\n","    m_nu = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_MASKS_AUG/MASKS_SP_\" + uuid + \".jpg\"\n","\n","    img = cv2.imread(fnid)\n","    mask = cv2.imread(mid)\n","\n","    img = cv2.imread(fnid)\n","    mask = cv2.imread(mid)\n","\n","    nimg = add_random_sp_noise(img, prop = 0.005)\n","\n","    a = cv2.imwrite(f_nu, nimg)\n","    b = cv2.imwrite(m_nu, mask)\n","\n","    if ((i % 10) == 0) or not a or not b:\n","        print(i, a, b)\n","    i += 1"],"metadata":{"id":"oxBsXLIQ_EVo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i = 0\n","for f in random.sample(imgs_list, 2500):\n","    uuid = ''.join(random.choices(string.ascii_uppercase + string.digits, k = 10))\n","    fid = \"0\" + re.search(r\"0(\\d+)\\.jpg\", f).group(1)\n","\n","    fnid = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_IMGS/ISIC_\" + fid + \".jpg\"\n","    mid = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_MASKS/ISIC_\" + fid + \"_segmentation.png\"\n","\n","    f_nu = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_IMGS_AUG/IMGS_CROP_SP_\" + uuid + \".jpg\"\n","    m_nu = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_MASKS_AUG/MASKS_CROP_SP_\" + uuid + \".jpg\"\n","\n","    img = cv2.imread(fnid)\n","    mask = cv2.imread(mid)\n","\n","    cimg, cmask = random_crop_selection(img, mask, 256, 256)\n","    nimg = add_random_sp_noise(cimg, prop = 0.005)\n","\n","    a = cv2.imwrite(f_nu, nimg)\n","    b = cv2.imwrite(m_nu, cmask)\n","\n","    if ((i % 10) == 0) or not a or not b:\n","        print(i, a, b)\n","    i += 1"],"metadata":{"id":"WKNCjkXsCdJL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i = 0\n","fnames = random.sample(imgs_list, 2500)\n","while i < 2500:\n","    f = fnames[i]\n","    uuid = ''.join(random.choices(string.ascii_uppercase + string.digits, k = 10))\n","    fid = \"0\" + re.search(r\"0(\\d+)\\.jpg\", f).group(1)\n","\n","    fnid = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_IMGS_CROP/ISIC_\" + fid + \".jpg\"\n","    mid = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_MASKS_CROP/ISIC_\" + fid + \"_segmentation.png\"\n","\n","    f_nu = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_IMGS_AUG/IMGS_ROT_SP_\" + uuid + \".jpg\"\n","    m_nu = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_MASKS_AUG/MASKS_ROT_SP_\" + uuid + \".jpg\"\n","\n","    img = cv2.imread(fnid)\n","    mask = cv2.imread(mid)\n","\n","    try:\n","        cimg, cmask = rand_flip_rot_scale(img, mask)\n","        nimg = add_random_sp_noise(cimg, prop = 0.005)\n","\n","        a = cv2.imwrite(f_nu, nimg)\n","        b = cv2.imwrite(m_nu, cmask)\n","\n","        if ((i % 10) == 0) or not a or not b:\n","            print(i, a, b)\n","        i += 1\n","    except:\n","        print(i, \"Rotate, Flip, Scale Failed\")"],"metadata":{"id":"UDpNJ0NgEgsb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i = 0\n","fnames = random.sample(imgs_list, 2500)\n","while i < 2500:\n","    f = fnames[i]\n","    uuid = ''.join(random.choices(string.ascii_uppercase + string.digits, k = 10))\n","    fid = \"0\" + re.search(r\"0(\\d+)\\.jpg\", f).group(1)\n","\n","    fnid = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_IMGS_CROP/ISIC_\" + fid + \".jpg\"\n","    mid = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_MASKS_CROP/ISIC_\" + fid + \"_segmentation.png\"\n","\n","    f_nu = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_IMGS_AUG/IMGS_BRIG_SP_\" + uuid + \".jpg\"\n","    m_nu = r\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_MASKS_AUG/MASKS_BRIG_SP_\" + uuid + \".jpg\"\n","\n","    img = cv2.imread(fnid)\n","    mask = cv2.imread(mid)\n","\n","    try:\n","        cimg = rand_brig_cont(img)\n","        nimg = add_random_sp_noise(cimg, prop = 0.005)\n","\n","        a = cv2.imwrite(f_nu, nimg)\n","        b = cv2.imwrite(m_nu, mask)\n","\n","        if ((i % 10) == 0) or not a or not b:\n","            print(i, a, b)\n","        i += 1\n","    except:\n","        print(i, \"Brightness, Constrast Failed\")"],"metadata":{"id":"rLd1D9zXKXot"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To make querying and loading data easier in the Dataset/Dataloader portion of the model notebook, included is a CSV that details an index, image path, and corresponding mask path."],"metadata":{"id":"DosLMqRvNjPF"}},{"cell_type":"code","source":["imgs_crop_list = glob.glob('/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_IMGS_CROP/*')\n","masks_crop_list = glob.glob('/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_MASKS_CROP/*')\n","imgs_aug_list = glob.glob('/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_IMGS_AUG/*')\n","masks_aug_list = glob.glob('/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_MASKS_AUG/*')"],"metadata":{"id":"OHVlmEXkNikD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["imgs_crop_list, masks_crop_list, imgs_aug_list, masks_aug_list = sorted(imgs_crop_list), sorted(masks_crop_list), sorted(imgs_aug_list), sorted(masks_aug_list)"],"metadata":{"id":"vcnpD5q8Yz-D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from skimage import io\n","from skimage.color import rgb2gray\n","import torchvision.transforms as T\n","import torch\n","t = rgb2gray(io.imread(masks_crop_list[0]))"],"metadata":{"id":"KcmLC199XByi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["c = T.ToTensor()(t).bool()\n","c_inv = ~c"],"metadata":{"id":"YDClHllXXMnf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["d = torch.cat((c.int(), (~c).int()), dim = 0)"],"metadata":{"id":"kr3ZI1xqXsKz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["d"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qlXapA_1ZBEe","executionInfo":{"status":"ok","timestamp":1714554545788,"user_tz":420,"elapsed":270,"user":{"displayName":"Christian A Granados","userId":"12347134257870755255"}},"outputId":"912fd82b-4aae-48de-fc3a-a8bf7d6f5711"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]],\n","\n","        [[1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         ...,\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1]]], dtype=torch.int32)"]},"metadata":{},"execution_count":175}]},{"cell_type":"code","source":["def img_to_mask_path(img):\n","\n","    start = \"/\".join(re.split(r\"/\", img)[:6])\n","\n","    # Augmented images\n","    if \"HAM10000_IMGS_AUG\" in img:\n","        mid = \"/HAM10000_MASKS_AUG/MASKS_\"\n","        end = \"_\".join(list(filter(lambda s: not (r\"/\" in s), img.split(\"_\")[-3:])))\n","\n","    # Original Images (Cropped)\n","    else:\n","        mid = \"/HAM10000_MASKS_CROP/ISIC_\"\n","        end = \"_\".join(masks_crop_list[10].split(\"_\")[-2:])\n","\n","    return start + mid + end"],"metadata":{"id":"fzQFta9YYXIE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a = defaultdict(lambda : 0)\n","res = pd.DataFrame(columns = [\"img_path\", \"mask_path\"])\n","\n","for mask in masks_crop_list + masks_aug_list:\n","    a[mask] = 1\n","\n","for img in imgs_crop_list + imgs_aug_list:\n","    cmask = img_to_mask_path(img)\n","    if not a[cmask]:\n","        print(\"Invalid:\", img, cmask)\n","    if a[cmask]:\n","        res.loc[len(res)] = {\"img_path\" : img, \"mask_path\" : cmask}\n"],"metadata":{"id":"ULa0nX2aODLM","executionInfo":{"status":"ok","timestamp":1714549948086,"user_tz":420,"elapsed":33340,"user":{"displayName":"Christian A Granados","userId":"12347134257870755255"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f6ba82af-b437-4c83-cbde-867d8752896a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_IMGS_AUG/IMGS_CROP_SP_78P9F51B37.jpg /content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_MASKS_AUG/MASKS_CROP_SP_78P9F51B37.jpg 0\n","/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_IMGS_AUG/IMGS_CROP_SP_VYHN05AGL9.jpg /content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/HAM10000_MASKS_AUG/MASKS_CROP_SP_VYHN05AGL9.jpg 0\n"]}]},{"cell_type":"code","source":["res.to_csv(\"/content/drive/MyDrive/Granados_Thesis_SP24/HAM10000/image_indexing.csv\", index = True, chunksize = 2500)"],"metadata":{"id":"msAdtyTfJf2A"},"execution_count":null,"outputs":[]}]}